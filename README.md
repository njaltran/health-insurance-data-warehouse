# Health Insurance Data Warehouse Project

Production-ready data cleaning and transformation pipelines for health and insurance data, built with dbt and BigQuery.

[![dbt](https://img.shields.io/badge/dbt-1.7+-orange.svg)](https://www.getdbt.com/)
[![BigQuery](https://img.shields.io/badge/BigQuery-enabled-blue.svg)](https://cloud.google.com/bigquery)
[![Data Engineering](https://img.shields.io/badge/Data%20Engineering-Best%20Practices-green.svg)](https://github.com)

## ğŸ“‹ Project Overview

This project implements a complete ELT (Extract-Load-Transform) data pipeline that cleans and validates health and insurance data following modern data engineering best practices from HWR Berlin's Data Warehouse course.

### **Key Features**

âœ… **39+ Automated Data Quality Tests**
âœ… **Production-Ready dbt Models** (Staging + Cleaned layers)
âœ… **Comprehensive Data Cleaning** (Deduplication, validation, standardization)
âœ… **BigQuery Optimized** (ELT pattern, schema-on-read)
âœ… **Full Documentation** (Data lineage, quality reports, troubleshooting)

---

## ğŸ—ï¸ Architecture

```
Raw Data (BigQuery)
    â†“
Staging Layer (Views) - Light transformation
    â†“
Cleaned Layer (Tables) - Full data quality
    â†“
BI Tools / ML Models / Analytics
```

### **Data Pipeline**

- **4 Source Tables** â†’ **4 Staging Views** â†’ **4 Cleaned Tables**
- **~10,000+ rows** transformed with quality validation
- **Data Quality Flags** for monitoring and observability

---

## ğŸ“Š Tables Created

| Table | Description | Rows | Tests |
|-------|-------------|------|-------|
| `sleep_health_cleaned` | Sleep & lifestyle metrics | ~320 | 11 |
| `smartwatch_data_cleaned` | Smartwatch health data | ~9,800 | 7 |
| `health_insurance_person_cleaned` | Person dimension | ~120 | 12 |
| `health_insurance_facts_cleaned` | Insurance facts | ~350 | 9 |

---

## ğŸš€ Quick Start

### **Prerequisites**

```bash
# Install dbt with BigQuery adapter
pip install dbt-bigquery

# Verify installation
dbt --version
```

### **Setup**

1. **Clone the repository:**
```bash
git clone <your-repo-url>
cd final_project
```

2. **Configure BigQuery connection:**

Create `~/.dbt/profiles.yml`:

```yaml
health_insurance:
  target: dev
  outputs:
    dev:
      type: bigquery
      method: oauth
      project: dw-health-insurance-bipm  # Update with your project ID
      dataset: raw_dataset
      threads: 4
      location: EU
```

3. **Install dbt packages:**
```bash
cd dbt_health_insurance
dbt deps
```

4. **Test connection:**
```bash
dbt debug
```

### **Run the Pipeline**

```bash
# Run all models (creates staging views + cleaned tables)
dbt run

# Run tests (executes 39+ quality checks)
dbt test

# Generate documentation
dbt docs generate
dbt docs serve
```

---

## ğŸ“ Project Structure

```
final_project/
â”œâ”€â”€ dbt_health_insurance/          # dbt project
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ staging/               # Staging layer (views)
â”‚   â”‚   â”‚   â”œâ”€â”€ stg_sleep_health.sql
â”‚   â”‚   â”‚   â”œâ”€â”€ stg_smartwatch_data.sql
â”‚   â”‚   â”‚   â”œâ”€â”€ stg_health_insurance_person.sql
â”‚   â”‚   â”‚   â”œâ”€â”€ stg_health_insurance_facts.sql
â”‚   â”‚   â”‚   â””â”€â”€ sources.yml
â”‚   â”‚   â””â”€â”€ cleaned/               # Cleaned layer (tables)
â”‚   â”‚       â”œâ”€â”€ sleep_health_cleaned.sql
â”‚   â”‚       â”œâ”€â”€ smartwatch_data_cleaned.sql
â”‚   â”‚       â”œâ”€â”€ health_insurance_person_cleaned.sql
â”‚   â”‚       â”œâ”€â”€ health_insurance_facts_cleaned.sql
â”‚   â”‚       â””â”€â”€ schema.yml         # Tests & documentation
â”‚   â”œâ”€â”€ macros/                    # Custom SQL macros
â”‚   â”œâ”€â”€ analyses/                  # Data quality reports
â”‚   â”œâ”€â”€ dbt_project.yml            # Project config
â”‚   â”œâ”€â”€ packages.yml               # Dependencies
â”‚   â”œâ”€â”€ README.md                  # dbt documentation
â”‚   â”œâ”€â”€ QUICKSTART.md              # Quick start guide
â”‚   â”œâ”€â”€ DATA_LINEAGE.md            # Lineage diagrams
â”‚   â””â”€â”€ TROUBLESHOOTING.md         # Common issues
â”œâ”€â”€ context/                       # Expert dossiers (reference)
â”œâ”€â”€ data_cleaning_scripts.sql      # Original SQL scripts
â”œâ”€â”€ PROJECT_SUMMARY.md             # Project overview
â””â”€â”€ README.md                      # This file
```

---

## ğŸ”§ Data Engineering Standards

This project implements the following best practices:

### **1. Schema & Types**
- âœ… SAFE_CAST to appropriate types (INT64, FLOAT64, DATE)
- âœ… Column names standardized to `snake_case`
- âœ… Complex field parsing (blood pressure: "131/86" â†’ systolic/diastolic)

### **2. Deduplication**
- âœ… Full-row duplicate removal using `ROW_NUMBER()`
- âœ… Primary key deduplication (person_id, user_id)
- âœ… Composite key deduplication (person_id + year)

### **3. Missing Values**
- âœ… Context-aware handling (dimensions: 'unknown', metrics: 0)
- âœ… `is_missing_*` flags for monitoring

### **4. Value Validation**
- âœ… Range checks (heart rate: 30-220, age: 0-120, etc.)
- âœ… Future date filtering
- âœ… Negative value removal
- âœ… `is_invalid_*` flags for tracking

### **5. Standardization**
- âœ… Text normalization (TRIM, LOWER, UPPER)
- âœ… Multi-format date parsing (5 different formats)
- âœ… Categorical value mapping (gender, status codes)

---

## ğŸ§ª Testing

The project includes **39+ automated data quality tests**:

```bash
# Run all tests
dbt test

# Test specific model
dbt test --select sleep_health_cleaned

# Run only uniqueness tests
dbt test --select test_type:unique
```

**Test Coverage:**
- Primary key uniqueness
- Referential integrity (foreign keys)
- Accepted values (categorical fields)
- Range validations (numeric fields)
- NOT NULL constraints
- Composite key uniqueness

---

## ğŸ“ˆ Data Quality Improvements

| Metric | Before (Raw) | After (Cleaned) |
|--------|--------------|-----------------|
| Duplicates | Yes | âŒ Removed |
| Date Formats | 5 different | âœ… Standardized |
| Gender Values | m, f, male, MALE, etc. | âœ… Standardized |
| NULL Handling | No strategy | âœ… Context-aware |
| Invalid Values | Heart rate=0, Age>150 | âœ… Filtered |
| Type Safety | All STRING | âœ… Proper types |
| Blood Pressure | Text "131/86" | âœ… Parsed (systolic/diastolic) |

---

## ğŸ“š Documentation

- **[dbt README](dbt_health_insurance/README.md)** - Comprehensive dbt documentation
- **[Quick Start Guide](dbt_health_insurance/QUICKSTART.md)** - Get started in 5 minutes
- **[Data Lineage](dbt_health_insurance/DATA_LINEAGE.md)** - Visual data flow diagrams
- **[Troubleshooting](dbt_health_insurance/TROUBLESHOOTING.md)** - Common issues & solutions
- **[Project Summary](PROJECT_SUMMARY.md)** - Complete project overview

---

## ğŸ” Data Lineage

View the complete data flow:

```bash
dbt docs generate
dbt docs serve
# Navigate to "Lineage" tab
```

Or see [DATA_LINEAGE.md](dbt_health_insurance/DATA_LINEAGE.md) for visual diagrams.

---

## ğŸ¯ Output

After running `dbt run`, cleaned data is available at:

```
Project: dw-health-insurance-bipm
â””â”€â”€ Dataset: raw_dataset
    â””â”€â”€ Schema: cleaned
        â”œâ”€â”€ sleep_health_cleaned
        â”œâ”€â”€ smartwatch_data_cleaned
        â”œâ”€â”€ health_insurance_person_cleaned
        â””â”€â”€ health_insurance_facts_cleaned
```

Query in BigQuery:
```sql
SELECT * FROM `dw-health-insurance-bipm.raw_dataset.cleaned.sleep_health_cleaned`;
```

---

## ğŸ¤ Contributing

This is an academic project for HWR Berlin's Data Warehouse course. For improvements:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/improvement`)
3. Commit changes (`git commit -m 'Add improvement'`)
4. Push to branch (`git push origin feature/improvement`)
5. Open a Pull Request

---

## ğŸ“– References

This project implements concepts from:

- **Expert Dossier 1:** Modern Data Architecture & Data Serving
- **Expert Dossier 2:** Extraction Strategies & CDC
- **Expert Dossier 3:** Transformation Logic & Data Quality Engineering
- **Expert Dossier 4:** Loading Strategies & History Management

### **Resources**
- [dbt Documentation](https://docs.getdbt.com/)
- [BigQuery Best Practices](https://cloud.google.com/bigquery/docs/best-practices)
- [Data Quality Dimensions](https://www.montecarlodata.com/blog-6-data-quality-dimensions-examples/)

---

## ğŸ“„ License

This project is for educational purposes as part of HWR Berlin's Data Warehouse course.

---

## ğŸ‘¤ Author

**Student:** Nikolas Jackaltran
**Institution:** HWR Berlin
**Course:** Data Warehouse
**Date:** January 2026

---

## ğŸ“ Acknowledgments

- Prof. Dr. Sebastian Fischer (HWR Berlin)
- Expert Dossiers 1-4 (Course Materials)
- dbt Labs (dbt framework)
- Google Cloud (BigQuery)

---

**Built with â¤ï¸ following Modern Data Engineering Best Practices**
